{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761582e2-1163-41a8-a127-c494d83ed747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16,VGG19,ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorlfow Version: \", tf.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42   # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39ab3e-96e4-429a-bb5b-0a0a718ba53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "base_dir = cwd\n",
    "data_dir = os.path.join(base_dir, '..', 'DATA', 'DogvsCat')\n",
    "trainpath = os.path.abspath(os.path.join(data_dir, 'train'))\n",
    "testpath = os.path.abspath(os.path.join(data_dir, 'test1', 'test1'))\n",
    "\n",
    "print(f\"Train path: {train_path}\")\n",
    "print(f\"Test path: {test_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06342d8-e4f1-4610-8478-989149212020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(trainpath)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# progress bar \n",
    "with tqdm(total=len(imagePaths)) as pbar:\n",
    "    \n",
    "    # loop over the input images\n",
    "    for idx, imagePath in enumerate(imagePaths):\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (48, 48))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "        if label == \"dog\":\n",
    "            label = 0\n",
    "        elif label == \"cat\":\n",
    "            label = 1\n",
    "\n",
    "        # print(\"pr: \", label)\t\n",
    "\n",
    "        labels.append(label)\n",
    "        \n",
    "        # update the progressbar\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09e786-c2e8-4230-9f25-21ecac841c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c6087-0f80-4876-ae0f-db59cbc51b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f8e03-eac6-48cd-9a26-c0416e8e8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.array(testX)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd10c8-c6e7-4884-a948-522675a6c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3d3e9-1f60-4abe-927b-7022e05aea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, \n",
    "                         width_shift_range=0.1, \n",
    "                         height_shift_range=0.1, \n",
    "                         shear_range=0.2, \n",
    "                         zoom_range=0.2, \n",
    "                         horizontal_flip=True, \n",
    "                         fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8f024-28cd-48e2-8338-fca93c2d4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de242bc4-4126-4c21-b4e8-03f5039afa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa057d-efaf-44ac-8c79-326e89a98101",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374023d-6c3b-4b26-9c4a-955086925e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(H, N, plotPath=None):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"acc_output.png\")\n",
    "\n",
    "def plot_loss(H, N, plotPath=None):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\"loss_output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b67c3c-bc70-4e9b-a5e9-4264b76d32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorlfow Version: \", tf.__version__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 43   # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8352d8e-0a89-4e5e-b64e-32c4ac7492cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)  # (h, h, channel)\n",
    "\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "\n",
    "        # first set of CONV => LeakyReLU => POOL layers\n",
    "        model.add(Conv2D(20, (4,4), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # second set of CONV => LeakyReLU => POOL layers\n",
    "        model.add(Conv2D(50, (4,4), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # third set of CONV => LeakyReLU => POOL layers\n",
    "        model.add(Conv2D(100, (4,4), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # first (and only) set of FC => LeakyReLU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(200))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b002bec-1410-4789-b085-09a52537a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = LeNet.build(width=48, height=48, depth=3, classes=2)\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] model complied...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fb45b-17e5-484f-95c3-614207e0e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=64),\n",
    "              validation_data=(testX, testY), \n",
    "              steps_per_epoch=len(trainX) // 64,\n",
    "              epochs=100, \n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf5272-623d-41a3-b501-ec7cb821b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dog_vs_cat_100_epochs.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab07140-7376-4e1b-815e-3638ad1ca4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model(\"dog_vs_cat_100_epochs.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e1341-cc90-4a0e-8edb-329b0e032e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(H,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013e513-8e0a-46ec-9199-768461d79884",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(H,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc31bdb-1aed-42cf-aaa0-a427d80fb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ce596-1924-457f-8320-c7d2d7bd5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img)\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138970f-3ad0-47b1-bf2b-8ec99afb599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the necessary packages\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(\"[INFO] loading network and...\")\n",
    "\n",
    "testImagePaths = sorted(list(paths.list_images(testpath)))   # data folder with 4 categorical folders\n",
    "\n",
    "all_class = [\"dog\", \"cat\"]\n",
    "\n",
    "\n",
    "# progress bar \n",
    "with tqdm(total=len(testImagePaths)) as pbar:\n",
    "    \n",
    "    for imagePath in testImagePaths:\n",
    "        \n",
    "        # load the image\n",
    "        image = cv2.imread(imagePath)\n",
    "        orig = image.copy()\n",
    "\n",
    "        # pre-process the image for classification\n",
    "        image = cv2.resize(image, (48, 48))\n",
    "        image = image.astype(\"float\") / 255.0\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        # classify the input image\n",
    "        prd_conf= model.predict(image)[0] # [[0.1 , 0.8 , 0.1]]\n",
    "        print(prd_conf)\n",
    "\n",
    "        # build the label\n",
    "        label = all_class[np.argmax(prd_conf)] #[b f s]-> f\n",
    "        proba = prd_conf[np.argmax(prd_conf)] # [0.1 , 0.8 , 0.1]  -> 0.8\n",
    "\n",
    "        label = \"{}: {:.2f}%\".format(label, proba * 100)\n",
    "\n",
    "        # draw the label on the image\n",
    "        output = imutils.resize(orig, width=400)\n",
    "        cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        # convert img to rgb format and display in notebook\n",
    "        img = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "        display_img(img)\n",
    "        \n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9ce03-cd1d-4f1c-aea0-d630e7ce26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d7245-0023-4b27-b953-1d0344800958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    # load the image\n",
    "    \n",
    "    # pre-process the image for classification\n",
    "    image = cv2.resize(image, (48, 48))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        \n",
    "    preds = model.predict(image)[0]\n",
    "    result = dict()\n",
    "    result[\"dog\"] = round(float(list(preds)[0]), 2)\n",
    "    result[\"cat\"] = round(float(list(preds)[1]), 2)\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929787f4-b75f-4f73-9ce6-525a48decd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = gr.inputs.Image(shape=(32,32))\n",
    "label = gr.outputs.Label(num_top_classes=2)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=im, outputs=label, capture_session=True, title=\"cat vs dog  Demo\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae6495-50f4-48f1-8ee1-7a55e2ad9a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
